{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPJsuoxeggTzex/o6TnSYm6",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/HarshPaba/naukriShala/blob/collab_work_upd/naukriShala.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "job_description=\"\"\"\n",
        "About the company:\n",
        "Smart Food Safe Solutions Inc. is a food safety compliance and resource management solution designed for global small to medium scale food processing industries by using domain-specific functional expertise in the form of latest internet-based smart technologies such as Blockchain, IoT, Cloud Computing, Machine learning, Artificial Intelligence, etc.\n",
        "\n",
        "About the internship/job:\n",
        "Selected intern's day-to-day responsibilities include: 1. Reviewing software requirements and preparing test cases 2. Execute test cases (manual or automated) and analyze results 3. Evaluate product code according to specifications 4. Report bugs and errors to development teams 5. Work with cross-functional teams to ensure quality throughout the software development lifecycle 6. Exposure to regression, API or performance testing tools will be added advantage\n",
        "\n",
        "Who can apply:\n",
        "Only those students or freshers can apply who:\n",
        "are available for full time (in-office) internship\n",
        "have relevant skills and interests\n",
        "can start the internship between 25th Mar'20 and 24th Apr'20\n",
        "are available for duration of 6 months\n",
        "have already graduated or are currently in any year of study\n",
        "Females willing to start/restart their career may also apply\n",
        "\n",
        "Number of internships/jobs available: 2\n",
        "\n",
        "Categories: Software Testing,Computer Science,Engineering\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "ZWoC-PcyjvoL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "resume=\"\"\"\n",
        "Harsh Paba 8899966228 # harshpaba123@gmail.com ï Harsh Paba § Harsh Paba\n",
        "Education\n",
        "Thapar Institute of Engineering And Technology Patiala, Punjab\n",
        "B.E. Computer Engineering August 2020 - August 2024\n",
        "Major Elective: Data Science CGPA: 8.96\n",
        "Projects\n",
        "NaukriShala GitHub Live Project\n",
        "• Developed a NLP powered job recommender system that analyzes resumes, extracts skills, and suggests relevant job\n",
        "openings to enhance job search\n",
        "• Utilized web scraping techniques to gather job openings from the internet and store them for convenient access\n",
        "• Used Streamlit platform to host and deploy the web application\n",
        "• Tech Stack Python, NLTK, StreamLit, BeautifulSoup\n",
        "Facial Attendance System GitHub\n",
        "• Created a smart attendance system that utilizes facial recognition technology to enable effortless and hands-free\n",
        "attendance tracking\n",
        "• Enables quick and easy enrollment of attendees by capturing multiple facial images\n",
        "• Creates separate, accurate attendance lists for each instance\n",
        "• Tech Stack Computer Vision, OpenCV\n",
        "ECG Anomaly Detection GitHub Google Colab\n",
        "• Built a deep learning based model to identify anomalies in ECG signals, enhancing the detection of abnormalities\n",
        "• Leveraged auto-encoder architecture to enhance the model’s accuracy\n",
        "• Achieved a 94% accuracy rate, demonstrating the effectiveness of the developed model\n",
        "• Tech Stack Python, Pandas, Sci-kit Learn, TensorFlow\n",
        "Experience\n",
        "Samsung Prism\n",
        "Research Intern Oct’22 - June’23\n",
        "∗ Collaborated with college professors and Samsung officials as part of a work-let to solve real world problems\n",
        "∗ Actively involved in analyzing time series data to uncover patterns, trends, and find anomalies\n",
        "∗ Implemented techniques to improve model performance and address class imbalance issues\n",
        "∗ Tech Stack Python, Machine Learning, Deep Learning\n",
        "Technical Skills\n",
        "Languages: C/C++, Python, HTML/CSS, MySql\n",
        "Key Courses: Object Oriented Programming (OOP), Data Structures & Algorithms, Operating Systems,\n",
        "Database Management, Computer Networks, Machine Learning\n",
        "Technologies/Frameworks: Git, Github, Scikitlearn\n",
        "Coding Profiles: Leetcode, GFG\n",
        "Achievements\n",
        "∗ Secured first runner-up position in HackX Hackathon DevFolio\n",
        "∗ Bagged 2nd position in Digital Village Hackathon DevFolio\n",
        "∗ Received merit scholarships I & II for maintaining a merit position in the universit\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "kGDQz8XQCDOZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize, sent_tokenize\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "data=job_description\n",
        "# Tokenize sentences and words\n",
        "sentences = sent_tokenize(data)\n",
        "words = [word_tokenize(sentence) for sentence in sentences]\n",
        "\n",
        "# Initialize NLTK's stopwords and lemmatizer\n",
        "stop_words = set(stopwords.words('english'))\n",
        "lemmatizer = WordNetLemmatizer()\n",
        "\n",
        "# Preprocess text\n",
        "preprocessed_data = []\n",
        "for sentence in words:\n",
        "    filtered_words = [lemmatizer.lemmatize(word.lower()) for word in sentence if word.isalnum() and word.lower() not in stop_words]\n",
        "    preprocessed_data.append(' '.join(filtered_words))\n",
        "\n",
        "# Print preprocessed data\n",
        "new_jd=\"\"\n",
        "for sentence in preprocessed_data:\n",
        "    new_jd=new_jd+\" \"+sentence\n"
      ],
      "metadata": {
        "id": "W3Hudsd89P1b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "new_jd"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 139
        },
        "id": "iOu79iJHXB-z",
        "outputId": "cc6bed6f-a290-4fbb-c255-c3fee0c66321"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "' company smart food safe solution food safety compliance resource management solution designed global small medium scale food processing industry using functional expertise form latest smart technology blockchain iot cloud computing machine learning artificial intelligence etc selected intern responsibility include 1 reviewing software requirement preparing test case 2 execute test case manual automated analyze result 3 evaluate product code according specification 4 report bug error development team 5 work team ensure quality throughout software development lifecycle 6 exposure regression api performance testing tool added advantage apply student fresher apply available full time internship relevant skill interest start internship 25th 24th available duration 6 month already graduated currently year study female willing career may also apply number available 2 category software testing computer science engineering'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 105
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data=resume\n",
        "# Tokenize sentences and words\n",
        "sentences = sent_tokenize(data)\n",
        "words = [word_tokenize(sentence) for sentence in sentences]\n",
        "\n",
        "# Initialize NLTK's stopwords and lemmatizer\n",
        "stop_words = set(stopwords.words('english'))\n",
        "lemmatizer = WordNetLemmatizer()\n",
        "\n",
        "# Preprocess text\n",
        "preprocessed_data = []\n",
        "for sentence in words:\n",
        "    filtered_words = [lemmatizer.lemmatize(word.lower()) for word in sentence if word.isalnum() and word.lower() not in stop_words]\n",
        "    preprocessed_data.append(' '.join(filtered_words))\n",
        "\n",
        "new_res=\"\"\n",
        "for sentence in preprocessed_data:\n",
        "    new_res=new_res+\" \"+sentence"
      ],
      "metadata": {
        "id": "VP72ZSv995Zm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "new_res"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 139
        },
        "id": "i-ziAj9aXh8t",
        "outputId": "233100de-9ab7-49f4-a6a1-00227f17e56f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "' harsh paba 8899966228 harshpaba123 ï harsh paba harsh paba education thapar institute engineering technology patiala punjab computer engineering august 2020 august 2024 major elective data science cgpa project naukrishala github live project developed nlp powered job recommender system analyzes resume extract skill suggests relevant job opening enhance job search utilized web scraping technique gather job opening internet store convenient access used streamlit platform host deploy web application tech stack python nltk streamlit beautifulsoup facial attendance system github created smart attendance system utilizes facial recognition technology enable effortless attendance tracking enables quick easy enrollment attendee capturing multiple facial image creates separate accurate attendance list instance tech stack computer vision opencv ecg anomaly detection github google colab built deep learning based model identify anomaly ecg signal enhancing detection abnormality leveraged architecture enhance model accuracy achieved 94 accuracy rate demonstrating effectiveness developed model tech stack python panda learn tensorflow experience samsung prism research intern oct 22 june 23 collaborated college professor samsung official part solve real world problem actively involved analyzing time series data uncover pattern trend find anomaly implemented technique improve model performance address class imbalance issue tech stack python machine learning deep learning technical skill language python mysql key course object oriented programming oop data structure algorithm operating system database management computer network machine learning git github scikitlearn coding profile leetcode gfg achievement secured first position hackx hackathon devfolio bagged 2nd position digital village hackathon devfolio received merit scholarship ii maintaining merit position universit'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 107
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# !pip install skillNer"
      ],
      "metadata": {
        "id": "FQTlJ_UK3HY-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# !python -m spacy download en_core_web_lg\n",
        "# nltk.download('wordnet')"
      ],
      "metadata": {
        "id": "iMzfEqgK3IWH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import spacy\n",
        "from spacy.matcher import PhraseMatcher\n",
        "\n",
        "# load default skills data base\n",
        "from skillNer.general_params import SKILL_DB\n",
        "# import skill extractor\n",
        "from skillNer.skill_extractor_class import SkillExtractor\n",
        "\n",
        "# init params of skill extractor\n",
        "nlp = spacy.load(\"en_core_web_lg\")\n",
        "# init skill extractor\n",
        "skill_extractor = SkillExtractor(nlp, SKILL_DB, PhraseMatcher)\n",
        "annotations_jd = skill_extractor.annotate(new_jd)\n",
        "skill_extractor = SkillExtractor(nlp, SKILL_DB, PhraseMatcher)\n",
        "annotations_res = skill_extractor.annotate(new_res)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5bkGfNN23Vuj",
        "outputId": "f57fb1dd-4f51-4487-c663-55078aacf26f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loading full_matcher ...\n",
            "loading abv_matcher ...\n",
            "loading full_uni_matcher ...\n",
            "loading low_form_matcher ...\n",
            "loading token_matcher ...\n",
            "loading full_matcher ...\n",
            "loading abv_matcher ...\n",
            "loading full_uni_matcher ...\n",
            "loading low_form_matcher ...\n",
            "loading token_matcher ...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/skillNer/utils.py:99: UserWarning: [W008] Evaluating Token.similarity based on empty vectors.\n",
            "  vec_similarity = token1.similarity(token2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "jd_skills=[]\n",
        "for x in annotations_jd['results']['ngram_scored']:\n",
        "  if(x['score']>=1):\n",
        "    jd_skills.append(x['doc_node_value'])\n",
        "for x in annotations_jd['results']['full_matches']:\n",
        "  if(x['score']>=1):\n",
        "    jd_skills.append(x['doc_node_value'])\n"
      ],
      "metadata": {
        "id": "-b31NWmtX-BQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "res_skills=[]\n",
        "for x in annotations_res['results']['ngram_scored']:\n",
        "  if(x['score']>=1):\n",
        "    res_skills.append(x['doc_node_value'])\n",
        "for x in annotations_res['results']['full_matches']:\n",
        "  if(x['score']>=1):\n",
        "    res_skills.append(x['doc_node_value'])"
      ],
      "metadata": {
        "id": "3cq2KBOiioH5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "res_skills=list(set(res_skills))\n",
        "jd_skills=list(set(jd_skills))"
      ],
      "metadata": {
        "id": "BuEzclZ2idEa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "jd_skills"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-DmIRSdCjG-j",
        "outputId": "82ba456b-8731-42dc-8d98-304e4f811403"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['machine learn',\n",
              " 'api',\n",
              " 'blockchain',\n",
              " 'food safety',\n",
              " 'added',\n",
              " 'processing industry',\n",
              " 'performance testing',\n",
              " 'solution design',\n",
              " 'safe',\n",
              " 'cloud computing',\n",
              " 'computer science',\n",
              " 'test case',\n",
              " 'food processing',\n",
              " 'scale',\n",
              " 'resource management',\n",
              " 'report bug',\n",
              " 'software development',\n",
              " 'artificial intelligence',\n",
              " 'software testing']"
            ]
          },
          "metadata": {},
          "execution_count": 114
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "res_skills"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BbgNlAD-jCZG",
        "outputId": "4f932638-f380-4f4c-de99-5a2193689c74"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['machine learn',\n",
              " 'computer vision',\n",
              " 'web application',\n",
              " 'data science',\n",
              " 'deploy web',\n",
              " 'opencv',\n",
              " 'programming',\n",
              " 'anomaly detection',\n",
              " 'tracking',\n",
              " 'recommender system',\n",
              " 'data structure',\n",
              " 'computer engineering',\n",
              " 'python',\n",
              " 'github',\n",
              " 'time series',\n",
              " 'prism',\n",
              " 'tensorflow',\n",
              " 'computer network',\n",
              " 'web scraping',\n",
              " 'deep learning',\n",
              " 'nltk',\n",
              " 'ecg',\n",
              " 'operating system',\n",
              " 'oop',\n",
              " 'facial recognition',\n",
              " 'research',\n",
              " 'mysql',\n",
              " 'beautifulsoup',\n",
              " 'git']"
            ]
          },
          "metadata": {},
          "execution_count": 115
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cnt=0;\n",
        "for x in res_skills:\n",
        "  for y in jd_skills:\n",
        "    if(x==y):\n",
        "      cnt+=1\n",
        "cnt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HIm8XaEzjNB3",
        "outputId": "9fff97a2-c799-416e-aa68-fc1f0a95a8b8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1"
            ]
          },
          "metadata": {},
          "execution_count": 116
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import spacy\n",
        "\n",
        "# nlp = spacy.load('en_core_web_md')\n",
        "\n",
        "cnt=0\n",
        "for word1 in res_skills:\n",
        "  for word2 in jd_skills:\n",
        "      token1 = nlp(word1)\n",
        "      token2 = nlp(word2)\n",
        "\n",
        "      # Calculate similarity using the .similarity() method\n",
        "      similarity = token1.similarity(token2)\n",
        "      if(similarity>=0.7):\n",
        "        print(f\"Similarity between '{word1}' and '{word2}': {similarity:.2f}\")\n",
        "        cnt+=1\n",
        "\n",
        "cnt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WNIil1dHlQXz",
        "outputId": "ed8c9d43-fc14-4b21-b81d-f6f0603aa58a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Similarity between 'machine learn' and 'machine learn': 1.00\n",
            "Similarity between 'computer vision' and 'computer science': 0.82\n",
            "Similarity between 'data science' and 'computer science': 0.80\n",
            "Similarity between 'computer engineering' and 'computer science': 0.89\n",
            "Similarity between 'computer engineering' and 'software development': 0.81\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-132-1c2a923e5973>:12: UserWarning: [W008] Evaluating Doc.similarity based on empty vectors.\n",
            "  similarity = token1.similarity(token2)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "5"
            ]
          },
          "metadata": {},
          "execution_count": 132
        }
      ]
    }
  ]
}